{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluaci√≥n Comprehensiva - Metodolog√≠a Completa**\n",
    "\n",
    "Sistema de evaluaci√≥n robusto con:\n",
    "- Benchmarks simples y complejos\n",
    "- M√∫ltiples heur√≠sticas de comparaci√≥n\n",
    "- An√°lisis estad√≠stico riguroso\n",
    "- Visualizaciones comparativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run librerias.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run benchmark_loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run gnn_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run heuristics.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. PREPARACI√ìN DE DATOS PARA GNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_datos_gnn(G):\n",
    "    \"\"\"\n",
    "    Convierte un grafo NetworkX a formato PyTorch Geometric.\n",
    "    \"\"\"\n",
    "    X = extraer_features(G)\n",
    "    X = normalizar_features(X)\n",
    "    \n",
    "    edge_index = np.array(list(G.edges())).T\n",
    "    \n",
    "    if edge_index.size == 0:\n",
    "        edge_index = np.array([[], []], dtype=np.int64)\n",
    "    \n",
    "    edge_index_reverse = np.array([edge_index[1], edge_index[0]])\n",
    "    edge_index_bidirectional = np.concatenate([edge_index, edge_index_reverse], axis=1)\n",
    "    \n",
    "    x_tensor = torch.FloatTensor(X)\n",
    "    edge_index_tensor = torch.LongTensor(edge_index_bidirectional)\n",
    "    \n",
    "    from torch_geometric.data import Data\n",
    "    data = Data(x=x_tensor, edge_index=edge_index_tensor)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. FUNCI√ìN DE COLORACI√ìN GREEDY PARA GNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_coloring_gnn(edge_index, num_nodes, ordering):\n",
    "    \"\"\"\n",
    "    Algoritmo greedy de coloraci√≥n dado un ordenamiento.\n",
    "    Compatible con edge_index de PyTorch Geometric.\n",
    "    \"\"\"\n",
    "    if isinstance(edge_index, torch.Tensor):\n",
    "        edge_index = edge_index.cpu().numpy()\n",
    "    \n",
    "    adj = {i: set() for i in range(num_nodes)}\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        u, v = edge_index[0, i], edge_index[1, i]\n",
    "        if u != v:\n",
    "            adj[u].add(v)\n",
    "            adj[v].add(u)\n",
    "    \n",
    "    coloring = {}\n",
    "    for node in ordering:\n",
    "        neighbor_colors = {coloring[v] for v in adj[node] if v in coloring}\n",
    "        \n",
    "        color = 0\n",
    "        while color in neighbor_colors:\n",
    "            color += 1\n",
    "        coloring[node] = color\n",
    "    \n",
    "    return max(coloring.values()) + 1 if coloring else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. EVALUADOR MULTI-HEUR√çSTICA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_todas_heuristicas(G, model=None, repeticiones=5):\n",
    "    \"\"\"\n",
    "    Eval√∫a m√∫ltiples heur√≠sticas en un grafo.\n",
    "    \n",
    "    Heur√≠sticas evaluadas:\n",
    "    1. Random (baseline)\n",
    "    2. Greedy Natural Order\n",
    "    3. Largest Degree First\n",
    "    4. Welsh-Powell\n",
    "    5. DSATUR\n",
    "    6. GNN-guided (si se proporciona modelo)\n",
    "    \"\"\"\n",
    "    resultados = []\n",
    "    \n",
    "    for _ in range(repeticiones):\n",
    "        order_random = ordenamiento_aleatorio(G)\n",
    "        t0 = time.time()\n",
    "        coloring_random = greedy_coloring(G, order_random)\n",
    "        t1 = time.time()\n",
    "        metrics_random = evaluar_coloracion(G, coloring_random)\n",
    "        resultados.append({\n",
    "            'metodo': 'Random',\n",
    "            'colores': metrics_random['num_colores'],\n",
    "            'tiempo': t1 - t0,\n",
    "            'valido': metrics_random['valido']\n",
    "        })\n",
    "    \n",
    "    order_natural = list(G.nodes())\n",
    "    t0 = time.time()\n",
    "    coloring_natural = greedy_coloring(G, order_natural)\n",
    "    t1 = time.time()\n",
    "    metrics_natural = evaluar_coloracion(G, coloring_natural)\n",
    "    resultados.append({\n",
    "        'metodo': 'Greedy Natural',\n",
    "        'colores': metrics_natural['num_colores'],\n",
    "        'tiempo': t1 - t0,\n",
    "        'valido': metrics_natural['valido']\n",
    "    })\n",
    "    \n",
    "    order_degree = ordenamiento_grado_desc(G)\n",
    "    t0 = time.time()\n",
    "    coloring_degree = greedy_coloring(G, order_degree)\n",
    "    t1 = time.time()\n",
    "    metrics_degree = evaluar_coloracion(G, coloring_degree)\n",
    "    resultados.append({\n",
    "        'metodo': 'Largest Degree First',\n",
    "        'colores': metrics_degree['num_colores'],\n",
    "        'tiempo': t1 - t0,\n",
    "        'valido': metrics_degree['valido']\n",
    "    })\n",
    "    \n",
    "    order_wp = ordenamiento_welsh_powell(G)\n",
    "    t0 = time.time()\n",
    "    coloring_wp = greedy_coloring(G, order_wp)\n",
    "    t1 = time.time()\n",
    "    metrics_wp = evaluar_coloracion(G, coloring_wp)\n",
    "    resultados.append({\n",
    "        'metodo': 'Welsh-Powell',\n",
    "        'colores': metrics_wp['num_colores'],\n",
    "        'tiempo': t1 - t0,\n",
    "        'valido': metrics_wp['valido']\n",
    "    })\n",
    "    \n",
    "    t0 = time.time()\n",
    "    coloring_dsatur = dsatur_coloring(G)\n",
    "    t1 = time.time()\n",
    "    metrics_dsatur = evaluar_coloracion(G, coloring_dsatur)\n",
    "    resultados.append({\n",
    "        'metodo': 'DSATUR',\n",
    "        'colores': metrics_dsatur['num_colores'],\n",
    "        'tiempo': t1 - t0,\n",
    "        'valido': metrics_dsatur['valido']\n",
    "    })\n",
    "    \n",
    "    if model is not None:\n",
    "        try:\n",
    "            data = preparar_datos_gnn(G)\n",
    "            model.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                scores = model(data.x, data.edge_index)\n",
    "                ordering = torch.argsort(scores, descending=True).tolist()\n",
    "            \n",
    "            t0 = time.time()\n",
    "            colores_gnn = greedy_coloring_gnn(data.edge_index, data.num_nodes, ordering)\n",
    "            t1 = time.time()\n",
    "            \n",
    "            resultados.append({\n",
    "                'metodo': 'GNN-guided',\n",
    "                'colores': colores_gnn,\n",
    "                'tiempo': t1 - t0,\n",
    "                'valido': True\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error en GNN: {e}\")\n",
    "    \n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. EVALUACI√ìN EN SUITE DE BENCHMARKS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_suite_completa(benchmarks, model=None, repeticiones=5):\n",
    "    \"\"\"\n",
    "    Eval√∫a todas las heur√≠sticas en una suite de benchmarks.\n",
    "    \"\"\"\n",
    "    resultados_completos = []\n",
    "    \n",
    "    for i, (G, nombre) in enumerate(benchmarks):\n",
    "        print(f\"\\n[{i+1}/{len(benchmarks)}] Evaluando: {nombre}\")\n",
    "        print(f\"  Nodos: {G.number_of_nodes()}, Aristas: {G.number_of_edges()}\")\n",
    "        \n",
    "        stats = estadisticas_grafo(G, nombre)\n",
    "        resultados_heuristicas = evaluar_todas_heuristicas(G, model, repeticiones)\n",
    "        \n",
    "        for res in resultados_heuristicas:\n",
    "            resultado_completo = {**stats, **res}\n",
    "            resultados_completos.append(resultado_completo)\n",
    "    \n",
    "    return pd.DataFrame(resultados_completos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. AN√ÅLISIS ESTAD√çSTICO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analisis_estadistico(df):\n",
    "    \"\"\"\n",
    "    Genera an√°lisis estad√≠stico de los resultados.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"AN√ÅLISIS ESTAD√çSTICO POR M√âTODO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    resumen = df.groupby('metodo').agg({\n",
    "        'colores': ['mean', 'std', 'min', 'max'],\n",
    "        'tiempo': ['mean', 'std'],\n",
    "        'valido': 'sum'\n",
    "    }).round(4)\n",
    "    \n",
    "    print(resumen)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RANKING DE M√âTODOS (por colores promedio)\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    ranking = df.groupby('metodo')['colores'].mean().sort_values()\n",
    "    for i, (metodo, colores) in enumerate(ranking.items(), 1):\n",
    "        print(f\"{i}. {metodo:20s} - {colores:.2f} colores promedio\")\n",
    "    \n",
    "    return resumen, ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. COMPARACI√ìN DETALLADA POR GRAFO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparacion_por_grafo(df):\n",
    "    \"\"\"\n",
    "    Muestra comparaci√≥n detallada por cada grafo.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARACI√ìN DETALLADA POR GRAFO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    grafos_unicos = df['nombre'].unique()\n",
    "    \n",
    "    for grafo in grafos_unicos:\n",
    "        df_grafo = df[df['nombre'] == grafo]\n",
    "        \n",
    "        print(f\"\\n{'‚îÄ'*80}\")\n",
    "        print(f\"Grafo: {grafo}\")\n",
    "        \n",
    "        info = df_grafo.iloc[0]\n",
    "        print(f\"  Nodos: {info['nodos']}, Aristas: {info['aristas']}, \"\n",
    "              f\"Densidad: {info['densidad']:.4f}, Grado m√°x: {info['grado_max']}\")\n",
    "        \n",
    "        if info['chi_teorico'] is not None:\n",
    "            print(f\"  œá(G) te√≥rico: {info['chi_teorico']}\")\n",
    "        print(f\"  Cota superior: Œî+1 = {info['cota_superior']}\")\n",
    "        \n",
    "        print(f\"\\n  Resultados por m√©todo:\")\n",
    "        \n",
    "        resumen_metodos = df_grafo.groupby('metodo').agg({\n",
    "            'colores': ['mean', 'min'],\n",
    "            'tiempo': 'mean'\n",
    "        }).round(4)\n",
    "        \n",
    "        for metodo in resumen_metodos.index:\n",
    "            colores_mean = resumen_metodos.loc[metodo, ('colores', 'mean')]\n",
    "            colores_min = resumen_metodos.loc[metodo, ('colores', 'min')]\n",
    "            tiempo = resumen_metodos.loc[metodo, ('tiempo', 'mean')]\n",
    "            print(f\"    {metodo:20s}: {colores_mean:6.2f} colores (min: {colores_min:.0f}) - {tiempo:.6f}s\")\n",
    "        \n",
    "        mejor_metodo = resumen_metodos[('colores', 'mean')].idxmin()\n",
    "        mejor_resultado = resumen_metodos.loc[mejor_metodo, ('colores', 'mean')]\n",
    "        print(f\"\\n  ‚úì Mejor m√©todo: {mejor_metodo} con {mejor_resultado:.2f} colores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. VISUALIZACI√ìN DE RESULTADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizar_resultados(df):\n",
    "    \"\"\"\n",
    "    Genera visualizaciones de los resultados.\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    resumen_metodos = df.groupby('metodo')['colores'].agg(['mean', 'std'])\n",
    "    resumen_metodos = resumen_metodos.sort_values('mean')\n",
    "    \n",
    "    axes[0, 0].barh(resumen_metodos.index, resumen_metodos['mean'], \n",
    "                     xerr=resumen_metodos['std'], capsize=5)\n",
    "    axes[0, 0].set_xlabel('N√∫mero de Colores (promedio)')\n",
    "    axes[0, 0].set_title('Comparaci√≥n de M√©todos - Colores Usados')\n",
    "    axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    tiempo_metodos = df.groupby('metodo')['tiempo'].mean().sort_values()\n",
    "    axes[0, 1].barh(tiempo_metodos.index, tiempo_metodos.values)\n",
    "    axes[0, 1].set_xlabel('Tiempo (segundos)')\n",
    "    axes[0, 1].set_title('Comparaci√≥n de M√©todos - Tiempo de Ejecuci√≥n')\n",
    "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    for metodo in df['metodo'].unique():\n",
    "        df_metodo = df[df['metodo'] == metodo]\n",
    "        axes[1, 0].scatter(df_metodo['nodos'], df_metodo['colores'], \n",
    "                          label=metodo, alpha=0.6)\n",
    "    axes[1, 0].set_xlabel('N√∫mero de Nodos')\n",
    "    axes[1, 0].set_ylabel('Colores Usados')\n",
    "    axes[1, 0].set_title('Escalabilidad - Nodos vs Colores')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(alpha=0.3)\n",
    "    \n",
    "    for metodo in df['metodo'].unique():\n",
    "        df_metodo = df[df['metodo'] == metodo]\n",
    "        axes[1, 1].scatter(df_metodo['densidad'], df_metodo['colores'], \n",
    "                          label=metodo, alpha=0.6)\n",
    "    axes[1, 1].set_xlabel('Densidad del Grafo')\n",
    "    axes[1, 1].set_ylabel('Colores Usados')\n",
    "    axes[1, 1].set_title('Densidad vs Colores')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('resultados_evaluacion.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n‚úì Gr√°ficos guardados en 'resultados_evaluacion.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. EJECUCI√ìN PRINCIPAL - EVALUACI√ìN SIMPLE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EVALUACI√ìN COMPREHENSIVA - NIVEL SIMPLE\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "benchmarks_simple = cargar_benchmark('suite', nivel='simple')\n",
    "print(f\"\\nBenchmarks cargados: {len(benchmarks_simple)}\")\n",
    "\n",
    "df_resultados_simple = evaluar_suite_completa(benchmarks_simple, model=None, repeticiones=3)\n",
    "\n",
    "resumen, ranking = analisis_estadistico(df_resultados_simple)\n",
    "comparacion_por_grafo(df_resultados_simple)\n",
    "\n",
    "try:\n",
    "    visualizar_resultados(df_resultados_simple)\n",
    "except Exception as e:\n",
    "    print(f\"\\nNo se pudieron generar gr√°ficos: {e}\")\n",
    "\n",
    "df_resultados_simple.to_csv('resultados_simple.csv', index=False)\n",
    "print(\"\\n‚úì Resultados guardados en 'resultados_simple.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. EJECUCI√ìN OPCIONAL - EVALUACI√ìN MEDIO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EVALUACI√ìN COMPREHENSIVA - NIVEL MEDIO\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "benchmarks_medio = cargar_benchmark('suite', nivel='medio')\n",
    "print(f\"\\nBenchmarks cargados: {len(benchmarks_medio)}\")\n",
    "\n",
    "df_resultados_medio = evaluar_suite_completa(benchmarks_medio, model=None, repeticiones=3)\n",
    "\n",
    "resumen_medio, ranking_medio = analisis_estadistico(df_resultados_medio)\n",
    "comparacion_por_grafo(df_resultados_medio)\n",
    "\n",
    "df_resultados_medio.to_csv('resultados_medio.csv', index=False)\n",
    "print(\"\\n‚úì Resultados guardados en 'resultados_medio.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. EJECUCI√ìN OPCIONAL - EVALUACI√ìN COMPLEJO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# EVALUACI√ìN COMPREHENSIVA - NIVEL COMPLEJO\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "benchmarks_complejo = cargar_benchmark('suite', nivel='complejo')\n",
    "print(f\"\\nBenchmarks cargados: {len(benchmarks_complejo)}\")\n",
    "\n",
    "df_resultados_complejo = evaluar_suite_completa(benchmarks_complejo, model=None, repeticiones=3)\n",
    "\n",
    "resumen_complejo, ranking_complejo = analisis_estadistico(df_resultados_complejo)\n",
    "comparacion_por_grafo(df_resultados_complejo)\n",
    "\n",
    "df_resultados_complejo.to_csv('resultados_complejo.csv', index=False)\n",
    "print(\"\\n‚úì Resultados guardados en 'resultados_complejo.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. RESUMEN FINAL Y CONCLUSIONES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# RESUMEN FINAL DE LA EVALUACI√ìN\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "print(\"\\nüìä METODOLOG√çA IMPLEMENTADA:\")\n",
    "print(\"  ‚úì Benchmarks simples: grafos cl√°sicos y peque√±os\")\n",
    "print(\"  ‚úì Benchmarks medios: redes sint√©ticas complejas (100 nodos)\")\n",
    "print(\"  ‚úì Benchmarks complejos: grafos grandes y desafiantes (500 nodos)\")\n",
    "print(\"  ‚úì Soporte para DIMACS y SNAP datasets\")\n",
    "\n",
    "print(\"\\nüî¨ HEUR√çSTICAS EVALUADAS:\")\n",
    "print(\"  1. Random (baseline)\")\n",
    "print(\"  2. Greedy Natural Order\")\n",
    "print(\"  3. Largest Degree First\")\n",
    "print(\"  4. Welsh-Powell\")\n",
    "print(\"  5. DSATUR\")\n",
    "print(\"  6. GNN-guided (cuando hay modelo entrenado)\")\n",
    "\n",
    "print(\"\\nüìà M√âTRICAS ANALIZADAS:\")\n",
    "print(\"  ‚Ä¢ N√∫mero de colores (promedio, std, min, max)\")\n",
    "print(\"  ‚Ä¢ Tiempo de ejecuci√≥n\")\n",
    "print(\"  ‚Ä¢ Validez de la coloraci√≥n\")\n",
    "print(\"  ‚Ä¢ Escalabilidad con tama√±o del grafo\")\n",
    "print(\"  ‚Ä¢ Comportamiento seg√∫n densidad\")\n",
    "\n",
    "print(\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "print(\"  ‚Ä¢ resultados_simple.csv\")\n",
    "print(\"  ‚Ä¢ resultados_medio.csv (opcional)\")\n",
    "print(\"  ‚Ä¢ resultados_complejo.csv (opcional)\")\n",
    "print(\"  ‚Ä¢ resultados_evaluacion.png\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
